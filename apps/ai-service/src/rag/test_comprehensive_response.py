"""
Test script to validate comprehensive response with improved chunk settings
"""
import os
import sys
from pathlib import Path

# Add the src directory to the Python path
current_dir = Path(__file__).parent
src_dir = current_dir.parent
sys.path.insert(0, str(src_dir))

from rag.retriever import MetadataEnhancedHybridRetriever
#!/usr/bin/env python3
"""
Test Comprehensive Response System - Cáº£i thiá»‡n cÃ¢u tráº£ lá»i Ä‘áº§y Ä‘á»§ hÆ¡n
"""

import os
import sys
from typing import List, Dict, Any

# Add project root to path
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(project_root)
sys.path.append(os.path.join(project_root, "src"))

from llm.config import LLMConfig, get_llm
import asyncio

async def test_comprehensive_grading_response():
    """Test comprehensive response about grading systems"""
    print("ğŸ”§ Testing comprehensive response with enhanced chunk settings...")
    
    # Initialize retriever with enhanced settings
    retriever = MetadataEnhancedHybridRetriever(
        data_path="d:/KMA_ChatBot_Frontend_System/chatbot_agent/data"
    )
    
    # Initialize vector database
    print("ğŸ“š Creating enhanced vector database...")
    vectorstore = retriever.create_enhanced_vector_database()
    
    # Test query about grading systems
    query = "cÃ¡c loáº¡i thang Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡"
    print(f"\nâ“ Query: {query}")
    
    # Retrieve relevant documents with increased context
    print("ğŸ” Retrieving relevant documents...")
    retrieved_docs = retriever.retrieve_with_metadata_filter(
        query=query,
        k=8,  # Increase number of retrieved docs
        metadata_filter=None
    )
    
    print(f"ğŸ“„ Retrieved {len(retrieved_docs)} documents")
    
    # Display retrieved content for analysis
    print("\nğŸ“‹ Retrieved Content Analysis:")
    for i, doc in enumerate(retrieved_docs):
        print(f"\n--- Document {i+1} ---")
        print(f"Source: {doc.metadata.get('source', 'Unknown')}")
        print(f"Content length: {len(doc.page_content)} characters")
        print(f"Content preview: {doc.page_content[:200]}...")
        if 'thang Ä‘iá»ƒm' in doc.page_content.lower():
            print("âœ… Contains grading scale information")
    
    # Initialize LLM
    print("\nğŸ¤– Initializing LLM...")
    llm = get_llm()
    
    # Create comprehensive context
    context = "\n\n".join([doc.page_content for doc in retrieved_docs])
    
    # Enhanced prompt for comprehensive response
    comprehensive_prompt = f"""
Dá»±a vÃ o thÃ´ng tin sau, hÃ£y tráº£ lá»i má»™t cÃ¡ch chi tiáº¿t vÃ  Ä‘áº§y Ä‘á»§ vá» cÃ¡c loáº¡i thang Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡:

{context}

CÃ¢u há»i: {query}

YÃªu cáº§u tráº£ lá»i:
- Liá»‡t kÃª Táº¤T Cáº¢ cÃ¡c loáº¡i thang Ä‘iá»ƒm Ä‘Æ°á»£c Ä‘á» cáº­p
- MÃ´ táº£ chi tiáº¿t tá»«ng loáº¡i thang Ä‘iá»ƒm
- Bao gá»“m cÃ¡c báº£ng quy Ä‘á»•i Ä‘iá»ƒm (náº¿u cÃ³)
- Giáº£i thÃ­ch cÃ¡c kÃ½ hiá»‡u Ä‘áº·c biá»‡t (I, X, etc.)
- Cung cáº¥p vÃ­ dá»¥ cá»¥ thá»ƒ cho má»—i loáº¡i thang Ä‘iá»ƒm

Tráº£ lá»i:
"""
    
    print("ğŸ’­ Generating comprehensive response...")
    response = await llm.generate_response(comprehensive_prompt)
    
    print("\n" + "="*80)
    print("ğŸ“ COMPREHENSIVE RESPONSE:")
    print("="*80)
    print(response)
    print("="*80)
    
    # Analyze response completeness
    print("\nğŸ“Š Response Analysis:")
    keywords_to_check = [
        "thang Ä‘iá»ƒm 10", "thang Ä‘iá»ƒm 4", "thang Ä‘iá»ƒm chá»¯",
        "quy Ä‘á»•i", "báº£ng Ä‘iá»ƒm", "A", "B", "C", "D", "F",
        "I", "X", "kÃ½ hiá»‡u"
    ]
    
    found_keywords = []
    for keyword in keywords_to_check:
        if keyword.lower() in response.lower():
            found_keywords.append(keyword)
    
    print(f"âœ… Found keywords: {found_keywords}")
    print(f"ğŸ“ˆ Coverage: {len(found_keywords)}/{len(keywords_to_check)} keywords")
    print(f"ğŸ“ Response length: {len(response)} characters")
    
    if len(found_keywords) >= len(keywords_to_check) * 0.7:
        print("ğŸ‰ Response appears comprehensive!")
    else:
        print("âš ï¸ Response may need improvement")

if __name__ == "__main__":
    asyncio.run(test_comprehensive_grading_response())