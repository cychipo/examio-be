"""
Department Graph Manager - ENHANCED WITH SEMANTIC SIMILARITY
Quáº£n lÃ½ graph riÃªng biá»‡t cho tá»«ng phÃ²ng ban/Ä‘Æ¡n vá»‹
Sá»­ dá»¥ng dual-signal approach vá»›i semantic similarity
"""
import os
import logging
from typing import Dict, List, Optional, Set, Any, Tuple
import networkx as nx
from langchain_core.documents import Document

from .graph_builder import DocumentGraph
from .subgraph_partitioner import SubgraphPartitioner
from .graph_retriever import GraphRoutedRetriever
from .semantic_department_detector import SemanticDepartmentDetector, DepartmentDecision

logger = logging.getLogger(__name__)


class DepartmentGraphManager:
    """
    Enhanced Department Graph Manager vá»›i semantic similarity
    Sá»­ dá»¥ng dual-signal approach Ä‘á»ƒ detect department chÃ­nh xÃ¡c hÆ¡n
    """
    
    def __init__(self, base_output_dir: str = "department_graphs"):
        self.base_output_dir = base_output_dir
        self.department_graphs: Dict[str, DocumentGraph] = {}
        self.department_partitioners: Dict[str, SubgraphPartitioner] = {}
        self.department_retrievers: Dict[str, GraphRoutedRetriever] = {}
        
        # Initialize semantic detector
        self.semantic_detector = SemanticDepartmentDetector(
            embeddings_dir=os.path.join(base_output_dir, "embeddings")
        )
        
        # Mapping phÃ²ng ban tá»« Ä‘Æ°á»ng dáº«n
        self.department_mapping = {
            'phongdaotao': ['phongdaotao', 'dao_tao', 'daotao'],
            'phongkhaothi': ['phongkhaothi', 'khao_thi', 'khaothi', 'chat_luong'],
            'khoa': ['khoa'],
            'viennghiencuuvahoptacphattrien': ['viennghiencuu', 'nghien_cuu', 'hop_tac'],
            'thongtinhvktmm': ['thongtin', 'hvktmm', 'hoc_vien'],
            'document_graph': ['giao_trinh', 'chung']  # TÃ i liá»‡u chung
        }
    
    def detect_department_from_path(self, file_path: str) -> str:
        """
        XÃ¡c Ä‘á»‹nh phÃ²ng ban tá»« Ä‘Æ°á»ng dáº«n file vá»›i logic cáº£i tiáº¿n
        """
        file_path_lower = file_path.lower().replace('\\', '/').replace(' ', '_')
        
        # Handle specific file patterns first
        filename = os.path.basename(file_path_lower)
        
        # Kháº£o thÃ­ patterns
        if any(keyword in filename for keyword in ['khao_thi', 'khaothi', 'chat_luong', 'dam_bao_chat_luong', 'quy_dinh_cong_tac_khao_thi']):
            return 'phongkhaothi'
        
        # ÄÃ o táº¡o patterns 
        if any(keyword in filename for keyword in ['dao_tao', 'daotao', 'quy_che_dao_tao', 'trinh_do_dai_hoc', 'tin_chi', 'nang_luc_tieng_anh']):
            return 'phongdaotao'
            
        # NghiÃªn cá»©u patterns
        if any(keyword in filename for keyword in ['khcn', 'nghien_cuu', 'hop_tac', 'phat_trien']):
            return 'viennghiencuuvahoptacphattrien'
            
        # ThÃ´ng tin HVKTMM patterns
        if any(keyword in filename for keyword in ['hoi_dong', 'hvktmm', 'hoc_vien']):
            return 'thongtinhvktmm'
        
        # Fallback to path-based detection
        
        for department, aliases in self.department_mapping.items():
            for alias in aliases:
                if alias in file_path_lower:
                    return department
        
        # Fallback: Check folder names
        path_parts = file_path_lower.split('/')
        for part in path_parts:
            for department, aliases in self.department_mapping.items():
                if part in aliases:
                    return department
        
        # Máº·c Ä‘á»‹nh: document_graph (Ä‘Ã£ bá» warning Ä‘á»ƒ giáº£m noise)
        return 'document_graph'  # Default
    
    def detect_department_smart(
        self, 
        query: str, 
        user_metadata: Dict[str, Any] = None,
        top_k: int = 2
    ) -> DepartmentDecision:
        """
        Smart department detection sá»­ dá»¥ng dual-signal approach
        """
        return self.semantic_detector.detect_department(query, user_metadata)
    
    def detect_department_from_query(self, query: str, top_k: int = 2) -> List[str]:
        """
        Legacy method - kept for backward compatibility
        Sá»­ dá»¥ng semantic detection nhÆ°ng tráº£ vá» format cÅ©
        """
        decision = self.semantic_detector.detect_department(query, user_metadata={'role': 'student'})
        
        # Náº¿u permission denied, fallback to document_graph
        if not decision.permission_granted:
            logger.warning(f"ğŸš« Permission denied for department {decision.chosen_department}")
            return ['document_graph']
        
        # Return chosen department + fallbacks
        result = [decision.chosen_department]
        
        # Add other high-confidence departments as fallbacks
        for signal in decision.signals:
            if (signal.department != decision.chosen_department and 
                signal.confidence > 0.3 and 
                signal.department not in result):
                result.append(signal.department)
        
        return result[:top_k]
        
    def build_department_graphs(self, documents: List[Document], dept_documents_override: Dict[str, List[Document]] = None) -> Dict[str, int]:
        """
        XÃ¢y dá»±ng graph riÃªng cho tá»«ng phÃ²ng ban tá»« documents
        ENHANCED: CÅ©ng build semantic embeddings cho tá»«ng department
        
        Args:
            documents: List of all documents
            dept_documents_override: Optional dict to override department document grouping
        
        Returns:
            Dict[department, node_count] - Thá»‘ng kÃª sá»‘ node má»—i phÃ²ng ban
        """
        logger.info("=" * 80)
        logger.info("ğŸ¢ BUILDING DEPARTMENT-SPECIFIC GRAPHS WITH SEMANTIC EMBEDDINGS")
        logger.info("=" * 80)

        # Use provided dept_documents or classify documents by department
        if dept_documents_override:
            dept_documents = dept_documents_override
            logger.info("ğŸ”„ Using provided department document grouping")
        else:
            # PhÃ¢n loáº¡i documents theo phÃ²ng ban using full_path - chá»‰ láº¥y docs trong thÆ° má»¥c phÃ²ng ban
            dept_documents = {}
            for doc in documents:
                # Use full_path if available, fallback to source
                source_path = doc.metadata.get('full_path', doc.metadata.get('source', ''))
                
                # Skip documents without folder structure (root level files)
                if '/' not in source_path and '\\' not in source_path:
                    continue
                
                # Check if it's actually in a department folder, not just detected by keywords
                path_lower = source_path.lower().replace('\\', '/')
                folder_depth = doc.metadata.get('folder_depth', 0)
                
                # Skip if folder_depth is 0 (root level files like "Giao trinh _ Pháº§n má»m mÃ£ nguá»“n má»Ÿ.md")
                if folder_depth == 0:
                    continue
                
                dept = self.detect_department_from_path(source_path)
                
                # Skip document_graph (general documents without specific department folder)
                if dept == 'document_graph':
                    continue
                
                if dept not in dept_documents:
                    dept_documents[dept] = []
                dept_documents[dept].append(doc)
                dept_documents[dept] = []
            dept_documents[dept].append(doc)
        
        # Thá»‘ng kÃª
        logger.info(f"ğŸ“Š Documents by department:")
        for dept, docs in dept_documents.items():
            logger.info(f"   {dept}: {len(docs)} documents")
        
        # Build semantic embeddings for departments
        logger.info("\nğŸ§  Building semantic embeddings for departments...")
        try:
            self.semantic_detector.build_department_embeddings(dept_documents)
            logger.info("âœ… Semantic embeddings built successfully")
        except Exception as e:
            logger.warning(f"âš ï¸ Could not build semantic embeddings: {e}")
            logger.info("Will continue with keyword-based detection")
        
        # XÃ¢y dá»±ng graph cho tá»«ng phÃ²ng ban
        stats = {}
        os.makedirs(self.base_output_dir, exist_ok=True)
        
        for dept, docs in dept_documents.items():
            if len(docs) == 0:
                logger.warning(f"âš ï¸  Skipping {dept}: No documents")
                continue
                
            logger.info(f"\nğŸ—ï¸  Building graph for {dept}...")
            
            try:
                # Create department-specific output directory
                dept_output_dir = os.path.join(self.base_output_dir, f"{dept}_graph")
                os.makedirs(dept_output_dir, exist_ok=True)
                
                # Build graph cho department nÃ y
                graph_builder = DocumentGraph(
                    semantic_threshold=0.7,
                    max_semantic_edges_per_node=7
                )
                
                # Build the graph
                graph = graph_builder.build_graph(docs)
                
                # Save the graph
                graph_path = os.path.join(dept_output_dir, f"{dept}_graph.pkl")
                graph_builder.save_graph(graph_path)
                
                # LÆ°u graph vÃ  táº¡o partitioner/retriever
                self.department_graphs[dept] = graph_builder
                
                # Create subgraph partitioner
                partitioner = SubgraphPartitioner(graph)
                
                # Run community detection with summary generation (build mode)
                logger.info(f"ğŸ˜ï¸ Running community detection for {dept}...")
                partitioner.partition_by_community_detection(generate_summaries=True)
                logger.info(f"   âœ… Detected {len(partitioner.communities)} communities")
                
                self.department_partitioners[dept] = partitioner
                
                # Create retriever vá»›i advanced parameters
                retriever = GraphRoutedRetriever(
                    graph=graph,
                    partitioner=partitioner,
                    embeddings_model="nomic-embed-text:latest",
                    k=10,  # FINAL: Top-10 sent to LLM (balance context size)
                    internal_k=30,  # INTERNAL: Expand from 30*2.5=75 candidates
                    hop_depth=3,  # Moderate hop depth for good coverage
                    expansion_factor=2.5  # Balanced expansion
                )
                self.department_retrievers[dept] = retriever
                
                # Stats
                if hasattr(graph_builder, 'graph') and graph_builder.graph:
                    node_count = len(graph_builder.graph.nodes())
                    edge_count = len(graph_builder.graph.edges())
                    stats[dept] = node_count
                    
                    logger.info(f"   âœ… {dept}: {node_count} nodes, {edge_count} edges")
                else:
                    stats[dept] = 0
                    logger.warning(f"   âš ï¸  {dept}: No graph created")
                    
            except Exception as e:
                logger.error(f"   âŒ Error building graph for {dept}: {e}")
                stats[dept] = 0
        
        logger.info("\n" + "=" * 80)
        logger.info("âœ… DEPARTMENT GRAPHS BUILD COMPLETED")
        logger.info("=" * 80)
        
        total_nodes = sum(stats.values())
        logger.info(f"ğŸ“Š SUMMARY:")
        for dept, count in stats.items():
            percentage = (count / total_nodes * 100) if total_nodes > 0 else 0
            logger.info(f"   ğŸ“ {dept}: {count} nodes ({percentage:.1f}%)")
        
        logger.info(f"\nğŸ¯ NEXT STEPS:")
        logger.info(f"   â€¢ Test queries with: query_smart() method")
        logger.info(f"   â€¢ Use user metadata for department routing")
        logger.info(f"   â€¢ Semantic similarity will resolve conflicts automatically")
        
        return stats
    
    def load_existing_graphs(self) -> bool:
        """
        Load cÃ¡c graph Ä‘Ã£ build trÆ°á»›c Ä‘Ã³
        """
        if not os.path.exists(self.base_output_dir):
            logger.warning(f"Department graphs directory not found: {self.base_output_dir}")
            return False
        
        loaded_count = 0
        
        # Special handling for document_graph at root level
        document_graph_dir = "document_graph"
        if os.path.exists(document_graph_dir) and os.path.isdir(document_graph_dir):
            try:
                # Look for graph files in document_graph directory
                graph_path = None
                for file in os.listdir(document_graph_dir):
                    if file.endswith('.graphml') or file.endswith('.pkl'):
                        graph_path = os.path.join(document_graph_dir, file)
                        break
                
                if graph_path and os.path.exists(graph_path):
                    # Load the graph from file
                    graph_builder = DocumentGraph()
                    graph_builder.load_graph(graph_path)
                    graph = graph_builder.graph
                    
                    # Create partitioner and retriever
                    partitioner = SubgraphPartitioner(graph)
                    
                    # Run community detection without summary generation (load mode)
                    logger.info(f"ğŸ˜ï¸ Loading community detection for document_graph...")
                    partitioner.partition_by_community_detection(generate_summaries=False)
                    logger.info(f"   âœ… Loaded {len(partitioner.communities)} communities")
                    
                    retriever = GraphRoutedRetriever(
                        graph=graph,
                        partitioner=partitioner,
                        embeddings_model="nomic-embed-text:latest",
                        k=10,
                        internal_k=30,
                        hop_depth=3,
                        expansion_factor=2.5
                    )
                    
                    self.department_graphs['document_graph'] = graph_builder
                    self.department_partitioners['document_graph'] = partitioner
                    self.department_retrievers['document_graph'] = retriever
                    loaded_count += 1
                    
                    logger.info(f"âœ… Loaded graph for document_graph")
                
            except Exception as e:
                logger.error(f"âŒ Error loading document_graph: {e}")
        
        # Load regular department graphs from department_graphs directory
        for dept_name in os.listdir(self.base_output_dir):
            dept_dir = os.path.join(self.base_output_dir, dept_name)
            
            # Skip non-directories and embedding directory
            if not os.path.isdir(dept_dir) or dept_name == "embeddings":
                continue
            
            # Extract department name from directory name
            if dept_name.endswith('_graph'):
                dept = dept_name[:-6]  # Remove '_graph' suffix
            else:
                dept = dept_name
            
            try:
                # Look for graph files
                graph_path = None
                for file in os.listdir(dept_dir):
                    if file.endswith('.graphml') or file.endswith('.pkl'):
                        graph_path = os.path.join(dept_dir, file)
                        break
                
                if graph_path and os.path.exists(graph_path):
                    # Load the graph from file
                    graph_builder = DocumentGraph()
                    graph_builder.load_graph(graph_path)
                    graph = graph_builder.graph
                    
                    # Create partitioner and retriever vá»›i advanced parameters
                    partitioner = SubgraphPartitioner(graph)
                    
                    # Run community detection without summary generation (load mode)
                    logger.info(f"ğŸ˜ï¸ Loading community detection for {dept}...")
                    partitioner.partition_by_community_detection(generate_summaries=False)
                    logger.info(f"   âœ… Loaded {len(partitioner.communities)} communities")
                    
                    retriever = GraphRoutedRetriever(
                        graph=graph,
                        partitioner=partitioner,
                        embeddings_model="nomic-embed-text:latest",
                        k=10,  # FINAL: Top-10 sent to LLM (balance context size)
                        internal_k=30,  # INTERNAL: Expand from 30*2.5=75 candidates
                        hop_depth=3,  # Moderate hop depth for good coverage
                        expansion_factor=2.5  # Balanced expansion
                    )
                    
                    self.department_graphs[dept] = graph_builder
                    self.department_partitioners[dept] = partitioner
                    self.department_retrievers[dept] = retriever
                    loaded_count += 1
                    
                    logger.info(f"âœ… Loaded graph for {dept}")
                
            except Exception as e:
                logger.error(f"âŒ Error loading graph for {dept}: {e}")
        
        if loaded_count > 0:
            logger.info(f"âœ… Successfully loaded {loaded_count} department graphs")
            return True
        else:
            logger.warning("âŒ No department graphs could be loaded")
            return False
    
    def query_smart(
        self,
        query: str,
        user_metadata: Dict[str, Any] = None,
        k: int = 5
    ) -> Tuple[List[str], DepartmentDecision]:
        """
        Enhanced query method sá»­ dá»¥ng semantic department detection
        
        Returns:
            Tuple[results, department_decision]
        """
        logger.info(f"ğŸ§  SMART QUERY with semantic routing")
        
        # Step 1: Detect department using dual-signal approach
        decision = self.detect_department_smart(query, user_metadata)
        
        # Step 2: Check permission
        if not decision.permission_granted:
            logger.warning(f"ğŸš« Access denied to {decision.chosen_department}")
            return [
                f"Xin lá»—i, báº¡n khÃ´ng cÃ³ quyá»n truy cáº­p thÃ´ng tin cá»§a phÃ²ng {decision.chosen_department}. "
                "Vui lÃ²ng liÃªn há»‡ quáº£n trá»‹ viÃªn Ä‘á»ƒ Ä‘Æ°á»£c cáº¥p quyá»n."
            ], decision
        
        # Step 3: Query trong department graph
        target_dept = decision.chosen_department
        logger.info(f"ğŸ—‚ï¸ USING GRAPH: {target_dept.upper()} (confidence: {decision.confidence:.3f})")
        
        if target_dept not in self.department_retrievers:
            logger.warning(f"âš ï¸ No retriever for department {target_dept}, trying to load...")
            
            if not self.load_existing_graphs():
                return [
                    f"Xin lá»—i, khÃ´ng tÃ¬m tháº¥y cÆ¡ sá»Ÿ dá»¯ liá»‡u cho phÃ²ng {target_dept}. "
                    "Vui lÃ²ng liÃªn há»‡ quáº£n trá»‹ viÃªn."
                ], decision
        
        try:
            retriever = self.department_retrievers[target_dept]
            results = retriever._get_relevant_documents(query)
            
            logger.info(f"âœ… Retrieved {len(results)} results from {target_dept}")
            
            return [doc.page_content for doc in results[:k]], decision
            
        except Exception as e:
            logger.error(f"âŒ Error querying {target_dept}: {e}")
            
            # Fallback: try document_graph department
            if target_dept != 'document_graph' and 'document_graph' in self.department_retrievers:
                logger.info("ğŸ”„ Fallback to document_graph department")
                logger.info(f"ğŸ—‚ï¸ USING GRAPH: DOCUMENT_GRAPH (fallback from {target_dept.upper()})")
                try:
                    retriever = self.department_retrievers['document_graph']
                    results = retriever._get_relevant_documents(query)
                    return [doc.page_content for doc in results[:k]], decision
                except Exception as e2:
                    logger.error(f"âŒ Fallback also failed: {e2}")
            
            return [
                f"Xin lá»—i, Ä‘Ã£ xáº£y ra lá»—i khi tÃ¬m kiáº¿m thÃ´ng tin: {str(e)}"
            ], decision
    
    def query_cross_department(
        self,
        query: str,
        user_metadata: Dict[str, Any] = None,
        departments: List[str] = None,
        k: int = 5
    ) -> Tuple[List[str], List[str]]:
        """
        Query across multiple departments (for admin users)
        
        Returns:
            Tuple[results, searched_departments]
        """
        if departments is None:
            departments = list(self.department_retrievers.keys())
        
        # Check admin permission
        user_role = user_metadata.get('role', 'student') if user_metadata else 'student'
        if user_role.lower() != 'admin':
            logger.warning(f"ğŸš« Cross-department query denied for role: {user_role}")
            return [
                "Báº¡n khÃ´ng cÃ³ quyá»n tÃ¬m kiáº¿m trÃªn nhiá»u phÃ²ng ban. "
                "Chá»©c nÄƒng nÃ y chá»‰ dÃ nh cho quáº£n trá»‹ viÃªn."
            ], []
        
        all_results = []
        searched_departments = []
        
        for dept in departments:
            if dept in self.department_retrievers:
                logger.info(f"ğŸ—‚ï¸ USING GRAPH: {dept.upper()}")
                try:
                    retriever = self.department_retrievers[dept]
                    dept_results = retriever._get_relevant_documents(query)
                    
                    # Add department prefix to results
                    prefixed_results = [
                        f"[{dept.upper()}] {doc.page_content}" for doc in dept_results
                    ]
                    
                    all_results.extend(prefixed_results)
                    searched_departments.append(dept)
                    
                except Exception as e:
                    logger.error(f"âŒ Error querying {dept}: {e}")
        
        return all_results[:k], searched_departments
    
    def get_department_stats(self) -> Dict[str, Dict[str, Any]]:
        """
        Láº¥y thá»‘ng kÃª cÃ¡c department graphs
        """
        stats = {}
        
        for dept, retriever in self.department_retrievers.items():
            try:
                # Basic stats
                dept_stats = {
                    'available': True,
                    'has_semantic_embeddings': dept in self.semantic_detector.department_embeddings
                }
                
                # Try to get graph stats
                if hasattr(retriever, 'partitioner') and retriever.partitioner:
                    if hasattr(retriever.partitioner, 'graph'):
                        graph = retriever.partitioner.graph
                        # Calculate communities correctly
                        num_communities = len(retriever.partitioner.communities) if hasattr(retriever.partitioner, 'communities') else 0
                        dept_stats.update({
                            'nodes': len(graph.nodes()) if graph else 0,
                            'edges': len(graph.edges()) if graph else 0,
                            'communities': num_communities
                        })
                
                stats[dept] = dept_stats
                
            except Exception as e:
                stats[dept] = {
                    'available': False,
                    'error': str(e)
                }
        
        return stats