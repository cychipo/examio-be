"""
Model Manager Module Ä‘á»ƒ quáº£n lÃ½ cÃ¡c mÃ´ hÃ¬nh LLM khÃ¡c nhau.
"""
import os
from typing import Dict, Any, Optional
from dotenv import load_dotenv
from enum import Enum

# Load environment variables
load_dotenv()

class ModelType(str, Enum):
    HUGGINGFACE = "huggingface"
    OLLAMA = "ollama"
    GEMINI = "gemini"
    OTHER = "other"

class ModelManager:
    """Quáº£n lÃ½ cÃ¡c mÃ´ hÃ¬nh LLM vÃ  tham sá»‘ cá»§a chÃºng."""
    
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ModelManager, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
        
        # Skip MongoDB - chá»‰ dÃ¹ng runtime vÃ  environment variables
        self.client = None
        self.db = None
        
        # Cache cho active model
        self._active_model = None
        self._active_model_params = None
        
        # Runtime model override (sáº½ ghi Ä‘Ã¨ lÃªn DB config)
        self._runtime_model_type = None
        self._runtime_ollama_model = None
        self._runtime_gemini_model = None
        
        self._initialized = True
    
    def get_active_model(self) -> Dict[str, Any]:
        """
        Láº¥y thÃ´ng tin vá» mÃ´ hÃ¬nh Ä‘ang hoáº¡t Ä‘á»™ng.
        
        Returns:
            Dict[str, Any]: ThÃ´ng tin cá»§a mÃ´ hÃ¬nh Ä‘ang hoáº¡t Ä‘á»™ng, hoáº·c None náº¿u khÃ´ng cÃ³.
        """
        # Kiá»ƒm tra cache
        if self._active_model is not None:
            return self._active_model
        
        # Skip database - chá»‰ dÃ¹ng environment variables vÃ  runtime overrides
        model = None
        
        if model:
            # Convert ObjectId to string
            model["id"] = str(model["_id"])
            del model["_id"]
            
            # Cáº­p nháº­t cache
            self._active_model = model
            self._active_model_params = model.get("parameters", {})
            
            return model
        
        # Náº¿u khÃ´ng tÃ¬m tháº¥y model nÃ o Ä‘ang active, láº¥y model máº·c Ä‘á»‹nh tá»« env
        model_type = os.environ.get("DEFAULT_MODEL_TYPE", ModelType.HUGGINGFACE)
        
        default_model = {
            "id": "default",
            "name": os.environ.get("DEFAULT_MODEL_NAME", "LLaMA 3 (8B)"),
            "path": os.environ.get("DEFAULT_MODEL_PATH", "NousResearch/Hermes-2-Pro-Llama-3-8B"),
            "modelType": model_type,
            "isActive": True,
            "parameters": {
                "temperature": float(os.environ.get("DEFAULT_TEMPERATURE", "0.7")),
                "top_p": float(os.environ.get("DEFAULT_TOP_P", "0.9")),
                "top_k": int(os.environ.get("DEFAULT_TOP_K", "40")),
                "max_tokens": int(os.environ.get("DEFAULT_MAX_TOKENS", "2048")),
                "presence_penalty": float(os.environ.get("DEFAULT_PRESENCE_PENALTY", "0")),
                "frequency_penalty": float(os.environ.get("DEFAULT_FREQUENCY_PENALTY", "0")),
                "system_prompt": os.environ.get("DEFAULT_SYSTEM_PROMPT", "Báº¡n lÃ  trá»£ lÃ½ AI cá»§a Há»c viá»‡n Ká»¹ thuáº­t Máº­t mÃ£.")
            }
        }
        
        # ThÃªm thÃ´ng tin Ä‘áº·c thÃ¹ cho tá»«ng loáº¡i model
        if model_type == ModelType.GEMINI:
            default_model["api_key"] = os.environ.get("GEMINI_API_KEY", "")
            default_model["gemini_model"] = os.environ.get("DEFAULT_GEMINI_MODEL", "gemini-1.5-pro")
        elif model_type == ModelType.OLLAMA:
            default_model["ollama_model"] = os.environ.get("DEFAULT_OLLAMA_MODEL", "llama3")
            default_model["ollama_url"] = os.environ.get("OLLAMA_API_URL", "http://localhost:11434")
        elif model_type == ModelType.HUGGINGFACE:
            default_model["hf_token"] = os.environ.get("HF_TOKEN", "")
        
        self._active_model = default_model
        self._active_model_params = default_model.get("parameters", {})
        
        return default_model
    
    def get_model_parameter(self, param_name: str, default_value: Any = None) -> Any:
        """
        Láº¥y giÃ¡ trá»‹ cá»§a má»™t tham sá»‘ cá»¥ thá»ƒ tá»« mÃ´ hÃ¬nh Ä‘ang hoáº¡t Ä‘á»™ng.
        
        Args:
            param_name (str): TÃªn tham sá»‘ cáº§n láº¥y.
            default_value (Any, optional): GiÃ¡ trá»‹ máº·c Ä‘á»‹nh náº¿u tham sá»‘ khÃ´ng tá»“n táº¡i.
            
        Returns:
            Any: GiÃ¡ trá»‹ cá»§a tham sá»‘.
        """
        # Äáº£m báº£o Ä‘Ã£ cÃ³ active model parameters
        if self._active_model_params is None:
            self.get_active_model()
        
        # Láº¥y giÃ¡ trá»‹ tham sá»‘
        return self._active_model_params.get(param_name, default_value)
    
    def get_all_models(self):
        """
        KhÃ´ng cáº§n database - models Ä‘Æ°á»£c quáº£n lÃ½ qua runtime vÃ  environment.
        """
        return []
    
    def activate_model(self, model_id: str) -> bool:
        """
        KÃ­ch hoáº¡t má»™t mÃ´ hÃ¬nh cá»¥ thá»ƒ.
        
        Args:
            model_id (str): ID cá»§a mÃ´ hÃ¬nh cáº§n kÃ­ch hoáº¡t.
            
        Returns:
            bool: True náº¿u thÃ nh cÃ´ng, False náº¿u tháº¥t báº¡i.
        """
        try:
            # VÃ´ hiá»‡u hÃ³a táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh
            self.db.llm_models.update_many(
                {},
                {"$set": {"isActive": False}}
            )
            
            # KÃ­ch hoáº¡t mÃ´ hÃ¬nh Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh
            result = self.db.llm_models.update_one(
                {"_id": ObjectId(model_id)},
                {"$set": {"isActive": True}}
            )
            
            # Reset cache
            self._active_model = None
            self._active_model_params = None
            
            return result.modified_count > 0
        except Exception as e:
            print(f"Error activating model: {str(e)}")
            return False
    
    def update_model_params(self, model_id: str, params: Dict[str, Any]) -> bool:
        """
        Cáº­p nháº­t tham sá»‘ cho má»™t mÃ´ hÃ¬nh cá»¥ thá»ƒ.
        
        Args:
            model_id (str): ID cá»§a mÃ´ hÃ¬nh cáº§n cáº­p nháº­t.
            params (Dict[str, Any]): CÃ¡c tham sá»‘ má»›i.
            
        Returns:
            bool: True náº¿u thÃ nh cÃ´ng, False náº¿u tháº¥t báº¡i.
        """
        try:
            result = self.db.llm_models.update_one(
                {"_id": ObjectId(model_id)},
                {"$set": {"parameters": params}}
            )
            
            # Náº¿u model Ä‘ang active, reset cache
            active_model = self.get_active_model()
            if active_model and active_model.get("id") == model_id:
                self._active_model = None
                self._active_model_params = None
            
            return result.modified_count > 0
        except Exception as e:
            print(f"Error updating model parameters: {str(e)}")
            return False
    
    def create_model(self, model_data: Dict[str, Any]) -> Optional[str]:
        """
        Táº¡o má»™t mÃ´ hÃ¬nh má»›i.
        
        Args:
            model_data (Dict[str, Any]): ThÃ´ng tin mÃ´ hÃ¬nh má»›i.
            
        Returns:
            Optional[str]: ID cá»§a mÃ´ hÃ¬nh má»›i náº¿u thÃ nh cÃ´ng, None náº¿u tháº¥t báº¡i.
        """
        try:
            result = self.db.llm_models.insert_one(model_data)
            return str(result.inserted_id)
        except Exception as e:
            print(f"Error creating model: {str(e)}")
            return None
    
    def get_system_prompt(self) -> str:
        """
        Láº¥y system prompt tá»« mÃ´ hÃ¬nh Ä‘ang hoáº¡t Ä‘á»™ng.
        
        Returns:
            str: System prompt.
        """
        return self.get_model_parameter("system_prompt", "Báº¡n lÃ  trá»£ lÃ½ AI cá»§a Há»c viá»‡n Ká»¹ thuáº­t Máº­t mÃ£.")
    
    def get_model_path(self) -> str:
        """
        Láº¥y Ä‘Æ°á»ng dáº«n Ä‘áº¿n mÃ´ hÃ¬nh Ä‘ang hoáº¡t Ä‘á»™ng.
        
        Returns:
            str: ÄÆ°á»ng dáº«n Ä‘áº¿n mÃ´ hÃ¬nh.
        """
        active_model = self.get_active_model()
        if active_model:
            return active_model.get("path", os.environ.get("DEFAULT_MODEL_PATH", "NousResearch/Hermes-2-Pro-Llama-3-8B"))
        return os.environ.get("DEFAULT_MODEL_PATH", "NousResearch/Hermes-2-Pro-Llama-3-8B")
    
    def get_model_type(self) -> str:
        """
        Láº¥y loáº¡i cá»§a mÃ´ hÃ¬nh Ä‘ang hoáº¡t Ä‘á»™ng.
        
        Returns:
            str: Loáº¡i mÃ´ hÃ¬nh (huggingface, ollama, gemini, other)
        """
        active_model = self.get_active_model()
        if active_model:
            return active_model.get("modelType", ModelType.HUGGINGFACE)
        return os.environ.get("DEFAULT_MODEL_TYPE", ModelType.HUGGINGFACE)
    
    def get_gemini_info(self) -> Dict[str, Any]:
        """
        Láº¥y thÃ´ng tin cáº¥u hÃ¬nh cho Gemini.
        
        Returns:
            Dict[str, Any]: ThÃ´ng tin cáº¥u hÃ¬nh Gemini.
        """
        active_model = self.get_active_model()
        if active_model and active_model.get("modelType") == ModelType.GEMINI:
            return {
                "api_key": active_model.get("api_key", os.environ.get("GEMINI_API_KEY", "")),
                "model": active_model.get("gemini_model", os.environ.get("DEFAULT_GEMINI_MODEL", "gemini-1.5-pro"))
            }
        return {
            "api_key": os.environ.get("GEMINI_API_KEY", ""),
            "model": os.environ.get("DEFAULT_GEMINI_MODEL", "gemini-1.5-pro")
        }
    
    def get_ollama_info(self) -> Dict[str, Any]:
        """
        Láº¥y thÃ´ng tin cáº¥u hÃ¬nh cho Ollama.
        
        Returns:
            Dict[str, Any]: ThÃ´ng tin cáº¥u hÃ¬nh Ollama.
        """
        active_model = self.get_active_model()
        if active_model and active_model.get("modelType") == ModelType.OLLAMA:
            return {
                "model": active_model.get("ollama_model", os.environ.get("DEFAULT_OLLAMA_MODEL", "llama3")),
                "url": active_model.get("ollama_url", os.environ.get("OLLAMA_API_URL", "http://localhost:11434"))
            }
        return {
            "model": os.environ.get("DEFAULT_OLLAMA_MODEL", "llama3"),
            "url": os.environ.get("OLLAMA_API_URL", "http://localhost:11434")
        }
    
    def get_huggingface_info(self) -> Dict[str, Any]:
        """
        Láº¥y thÃ´ng tin cáº¥u hÃ¬nh cho Hugging Face.
        
        Returns:
            Dict[str, Any]: ThÃ´ng tin cáº¥u hÃ¬nh Hugging Face.
        """
        active_model = self.get_active_model()
        if active_model and active_model.get("modelType") == ModelType.HUGGINGFACE:
            return {
                "model": active_model.get("path", os.environ.get("DEFAULT_MODEL_PATH", "NousResearch/Hermes-2-Pro-Llama-3-8B")),
                "token": active_model.get("hf_token", os.environ.get("HF_TOKEN", ""))
            }
        return {
            "model": os.environ.get("DEFAULT_MODEL_PATH", "NousResearch/Hermes-2-Pro-Llama-3-8B"),
            "token": os.environ.get("HF_TOKEN", "")
        }
    
    def get_temperature(self) -> float:
        """
        Láº¥y giÃ¡ trá»‹ temperature tá»« mÃ´ hÃ¬nh Ä‘ang hoáº¡t Ä‘á»™ng.
        
        Returns:
            float: GiÃ¡ trá»‹ temperature.
        """
        return self.get_model_parameter("temperature", 0.7)
    
    def get_max_tokens(self) -> int:
        """
        Láº¥y giÃ¡ trá»‹ max_tokens tá»« mÃ´ hÃ¬nh Ä‘ang hoáº¡t Ä‘á»™ng.
        
        Returns:
            int: GiÃ¡ trá»‹ max_tokens.
        """
        return self.get_model_parameter("max_tokens", 2048)
    
    # ============ RUNTIME MODEL SWITCHING METHODS ============
    
    def set_active_model_type(self, model_type: ModelType) -> None:
        """
        Äáº·t loáº¡i model Ä‘ang hoáº¡t Ä‘á»™ng (runtime override).
        
        Args:
            model_type: Loáº¡i model cáº§n kÃ­ch hoáº¡t
        """
        self._runtime_model_type = model_type
        # Clear cache Ä‘á»ƒ force reload
        self._active_model = None
        self._active_model_params = None
        print(f"ğŸ”„ Runtime model type set to: {model_type}")
    
    def set_ollama_model(self, ollama_model: str) -> None:
        """
        Äáº·t model Ollama cá»¥ thá»ƒ (runtime override).
        
        Args:
            ollama_model: TÃªn model Ollama
        """
        self._runtime_ollama_model = ollama_model
        if self._runtime_model_type != ModelType.OLLAMA:
            self.set_active_model_type(ModelType.OLLAMA)
        print(f"ğŸ”„ Runtime Ollama model set to: {ollama_model}")
    
    def set_gemini_model(self, gemini_model: str) -> None:
        """
        Äáº·t model Gemini cá»¥ thá»ƒ (runtime override).
        
        Args:
            gemini_model: TÃªn model Gemini
        """
        self._runtime_gemini_model = gemini_model
        if self._runtime_model_type != ModelType.GEMINI:
            self.set_active_model_type(ModelType.GEMINI)
        print(f"ğŸ”„ Runtime Gemini model set to: {gemini_model}")
    
    def get_model_type(self) -> ModelType:
        """
        Láº¥y loáº¡i model Ä‘ang hoáº¡t Ä‘á»™ng (cÃ³ thá»ƒ lÃ  runtime override).
        
        Returns:
            ModelType: Loáº¡i model Ä‘ang hoáº¡t Ä‘á»™ng
        """
        # Æ¯u tiÃªn runtime override
        if self._runtime_model_type:
            return self._runtime_model_type
        
        # Fallback vá» environment variable
        if os.getenv("ACTIVE_MODEL_TYPE"):
            return ModelType(os.getenv("ACTIVE_MODEL_TYPE"))
        
        # Fallback vá» database hoáº·c default
        active_model = self.get_active_model()
        return ModelType(active_model.get("modelType", ModelType.GEMINI))
    
    def get_ollama_info(self) -> Dict[str, Any]:
        """
        Láº¥y thÃ´ng tin Ollama Ä‘ang hoáº¡t Ä‘á»™ng (cÃ³ thá»ƒ lÃ  runtime override).
        
        Returns:
            Dict[str, Any]: ThÃ´ng tin Ollama
        """
        # Æ¯u tiÃªn runtime override
        if self._runtime_ollama_model:
            return {
                "model": self._runtime_ollama_model,
                "url": os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
            }
        
        # Æ¯u tiÃªn environment variable
        if os.getenv("ACTIVE_OLLAMA_MODEL"):
            return {
                "model": os.getenv("ACTIVE_OLLAMA_MODEL"),
                "url": os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
            }
        
        # Fallback vá» RAG_MODEL tá»« env
        return {
            "model": os.getenv("RAG_MODEL", "qwen3:8b"),
            "url": os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        }
    
    def get_gemini_info(self) -> Dict[str, Any]:
        """
        Láº¥y thÃ´ng tin Gemini Ä‘ang hoáº¡t Ä‘á»™ng (cÃ³ thá»ƒ lÃ  runtime override).
        
        Returns:
            Dict[str, Any]: ThÃ´ng tin Gemini
        """
        # Æ¯u tiÃªn runtime override
        if self._runtime_gemini_model:
            return {
                "model": self._runtime_gemini_model,
                "api_key": os.getenv("GOOGLE_API_KEY", "")
            }
        
        # Æ¯u tiÃªn environment variable
        if os.getenv("ACTIVE_GEMINI_MODEL"):
            return {
                "model": os.getenv("ACTIVE_GEMINI_MODEL"),
                "api_key": os.getenv("GOOGLE_API_KEY", "")
            }
        
        # Fallback vá» GEMINI_MODEL tá»« env
        return {
            "model": os.getenv("GEMINI_MODEL", "gemini-2.0-flash"),
            "api_key": os.getenv("GOOGLE_API_KEY", "")
        }
    
    def clear_runtime_overrides(self) -> None:
        """
        XÃ³a táº¥t cáº£ runtime overrides vÃ  trá»Ÿ vá» cáº¥u hÃ¬nh máº·c Ä‘á»‹nh.
        """
        self._runtime_model_type = None
        self._runtime_ollama_model = None
        self._runtime_gemini_model = None
        self._active_model = None
        self._active_model_params = None
        print("ğŸ”„ Runtime overrides cleared")

# Singleton instance
model_manager = ModelManager()
