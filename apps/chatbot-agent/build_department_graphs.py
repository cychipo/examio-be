#!/usr/bin/env python3
"""
Build Department-Specific Document Graphs
X√¢y d·ª±ng graph ri√™ng bi·ªát cho t·ª´ng ph√≤ng ban thay v√¨ 1 graph chung
"""
import sys
import os
import time

# Add src to path
project_root = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(project_root, 'src')
if src_path not in sys.path:
    sys.path.insert(0, src_path)

from rag.table_aware_chunking import load_documents_from_folder
from graph_rag.department_graph_manager import DepartmentGraphManager

print("=" * 80)
print("üè¢ BUILDING DEPARTMENT-SPECIFIC DOCUMENT GRAPHS")
print("=" * 80)
print("M·ªói ph√≤ng ban s·∫Ω c√≥ graph ri√™ng, tr√°nh nhi·ªÖu t·ª´ ph√≤ng ban kh√°c")
print("User ch·ªâ query trong graph c·ªßa ph√≤ng ban t∆∞∆°ng ·ª©ng")
print()

# Path configurations
data_folder = os.path.join(project_root, "data")
output_folder = os.path.join(project_root, "department_graphs")

# Load t·∫•t c·∫£ documents
print(f"üìÅ Loading documents from: {data_folder}")
print("   Using enhanced table-aware chunking:")
print("   - Auto-detection of markdown tables")
print("   - Table preservation")
print("   - Vietnamese legal document structure awareness")
print("   - Department classification from file paths")
print()

start_time = time.time()
documents = load_documents_from_folder(
    data_folder=data_folder,
    chunk_size=800,
    chunk_overlap=200
)
load_time = time.time() - start_time

print(f"‚úÖ Loaded {len(documents)} document chunks in {load_time:.2f}s")

# Count special chunks
table_chunks = sum(1 for doc in documents if doc.metadata.get('contains_table', False))
if table_chunks > 0:
    print(f"   üìä {table_chunks} chunks contain markdown tables")
    print(f"   üìù {len(documents) - table_chunks} regular text chunks")

# Analyze document distribution by department
print("\nüìä Analyzing document distribution by department...")
dept_manager = DepartmentGraphManager(output_folder)

# Count documents per department
dept_counts = {}
for doc in documents:
    # Use full_path if available, fallback to source
    source_path = doc.metadata.get('full_path', doc.metadata.get('source', ''))
    dept = dept_manager.detect_department_from_path(source_path)
    dept_counts[dept] = dept_counts.get(dept, 0) + 1

print("   Documents by department (before building graphs):")
for dept, count in sorted(dept_counts.items()):
    print(f"   üìÅ {dept}: {count} documents")

# Build department-specific graphs
print(f"\nüî® Building department-specific graphs...")
print("   Settings per department:")
print("   - semantic_threshold=0.7 (balanced connectivity)")
print("   - max_edges=7 (rich connections)")
print("   - Louvain community detection")
print()

start_time = time.time()
department_stats = dept_manager.build_department_graphs(documents)
graph_build_time = time.time() - start_time

print(f"\n‚úÖ Department graphs built in {graph_build_time:.2f}s")

# Test loading graphs
print(f"\nüîç Testing graph loading...")
test_manager = DepartmentGraphManager(output_folder)
load_success = test_manager.load_existing_graphs()

if load_success:
    print("‚úÖ Graph loading test successful!")
    
    # Show final statistics
    final_stats = test_manager.get_department_stats()
    print(f"\nüìä Final Department Graph Statistics:")
    
    total_nodes = sum(stat['nodes'] for stat in final_stats.values())
    total_edges = sum(stat['edges'] for stat in final_stats.values())
    total_communities = sum(stat['communities'] for stat in final_stats.values())
    
    print(f"   üè¢ Total departments: {len(final_stats)}")
    print(f"   üìà Total nodes: {total_nodes}")
    print(f"   üìà Total edges: {total_edges}")
    print(f"   üèòÔ∏è  Total communities: {total_communities}")
    print()
    
    for dept, stats in final_stats.items():
        nodes = stats.get('nodes', 0)
        edges = stats.get('edges', 0)
        avg_degree = (2 * edges / nodes) if nodes > 0 else 0
        print(f"   üìÅ {dept}:")
        print(f"      - Nodes: {nodes}")
        print(f"      - Edges: {edges}")
        print(f"      - Communities: {stats.get('communities', 0)}")
        print(f"      - Avg degree: {avg_degree:.2f}")
    
    # Test smart query
    print(f"\nüß™ Testing smart query functionality...")
    test_queries = [
        "Quy ƒë·ªãnh v·ªÅ ƒëi·ªÉm TOEIC c·∫ßn thi·∫øt ƒë·ªÉ t·ªët nghi·ªáp",
        "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o ng√†nh ATTT", 
        "Quy tr√¨nh nghi√™n c·ª©u khoa h·ªçc",
        "Th√¥ng tin v·ªÅ H·ªçc vi·ªán K·ªπ thu·∫≠t m·∫≠t m√£"
    ]
    
    for query in test_queries:
        print(f"\nüîç Test query: {query}")
        target_depts = test_manager.detect_department_from_query(query, top_k=2)
        print(f"   üéØ Detected departments: {target_depts}")
        
        # Test actual retrieval
        results = test_manager.query_smart(query, k=2)
        print(f"   üìÑ Retrieved {len(results)} documents")
        
        if isinstance(results, list) and len(results) > 0:
            for i, doc in enumerate(results):
                if hasattr(doc, 'metadata'):
                    dept = doc.metadata.get('query_department', 'unknown')
                    source = os.path.basename(doc.metadata.get('source', 'unknown'))
                    print(f"      {i+1}. [{dept}] {source} (score: {doc.metadata.get('combined_score', 0):.3f})")
                else:
                    print(f"      {i+1}. Unexpected result type: {type(doc)}")
        else:
            print(f"      No valid documents retrieved")

else:
    print("‚ùå Graph loading test failed!")

print("\n" + "=" * 80)
print("‚úÖ DEPARTMENT GRAPH BUILDING COMPLETE!")
print("=" * 80)
print(f"Total time: {load_time + graph_build_time:.2f}s")
print(f"  - Document loading: {load_time:.2f}s")
print(f"  - Graph building: {graph_build_time:.2f}s")
print(f"Graphs saved to: {output_folder}")
print()
print("üéØ Usage:")
print("   1. Load graphs: manager = DepartmentGraphManager(); manager.load_department_graphs()")
print("   2. Smart query: results = manager.query_smart('your question', user_department='phongdaotao')")
print("   3. Specific dept: results = manager.query_department('question', 'phongkhaothi')")